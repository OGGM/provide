{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ba39e4-5273-4430-94ec-d008b1594abe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ccb7ff-38d4-4547-8a13-826c7039f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e52d576c-ae8c-4a23-9af8-c80722c822e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset('/home/www/pschmitt/provide/aggregate_data/github/provide/glacier_regions/total_data/aggregated_data/central_europe/central_europe_CurPol_map.nc') as ds:\n",
    "    ds = ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39c8794-46db-4a91-8dc1-057e80546774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isin([-0.5, 0.5], ds.lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16043214-d3e0-4740-86ac-7b9d1cb93dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go up until we are in the project base directory\n",
    "base_dir = os.getcwd()\n",
    "while base_dir.split('/')[-1] != 'provide':\n",
    "    base_dir = os.path.normpath(os.path.join(base_dir, '..'))\n",
    "\n",
    "# add paths for tools and data\n",
    "things_to_add = ['general_tools', 'aggregation_tools', 'general_data_for_aggregation']\n",
    "for thing in things_to_add:\n",
    "    sys.path.append(os.path.join(base_dir, thing))\n",
    "\n",
    "from general_tools import check_if_notebook, mkdir\n",
    "from oggm_result_filepath_and_realisations import scenarios_mesmer\n",
    "from aggregation_plots import plot_map, plot_timeseries, plot_unavoidable_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e9b0e3-4dd8-4343-b1dd-7273fb16169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to conditionally execute tests/debugging\n",
    "if check_if_notebook():\n",
    "    is_notebook = True\n",
    "else:\n",
    "    is_notebook = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be4688-17df-41ed-9de5-8b5fa0f26549",
   "metadata": {},
   "source": [
    "# define inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aab3070-22fe-4559-ad77-d0b1c13af553",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_dir = 'total_data'\n",
    "input_folder = 'aggregated_data'\n",
    "output_folder = 'aggregated_result_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6c266b-726a-4915-abe6-c6b9a884e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_region_dict_outpath = os.path.join(base_dir, 'glacier_regions', resolution_dir)\n",
    "\n",
    "with open(os.path.join(preprocess_region_dict_outpath, \"preprocessed_region_grids.json\"), 'r') as f:\n",
    "    region_structure_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2571f61a-3090-4912-963d-d1f79c10d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_data_dir = os.path.join(base_dir, 'glacier_regions', 'data')\n",
    "regions_file = 'glacier_regions.shp'\n",
    "gdf_regions = gpd.read_file(os.path.join(regions_data_dir, regions_file))\n",
    "name_col_regions = 'full_name'\n",
    "\n",
    "gdf_regions = gdf_regions.dissolve(by=name_col_regions)\n",
    "gdf_regions = gdf_regions.reset_index()\n",
    "\n",
    "gdf_regions[name_col_regions] = gdf_regions[name_col_regions].str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f387f-dc9a-4cb4-b1bc-34555790a38f",
   "metadata": {},
   "source": [
    "# plot for all regions and scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7038f3-df12-430d-99c9-27b5da38a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scenario_results_region(region_name, scenario, input_folder, output_folder,\n",
    "                                 add_map_plot=True, resolution=None\n",
    "                                ):\n",
    "    plot_output_folder = os.path.join(output_folder, region_name)\n",
    "    mkdir(plot_output_folder)\n",
    "    region = gdf_regions[gdf_regions[name_col_regions] == region_name]\n",
    "\n",
    "    if add_map_plot:\n",
    "        plot_map(region, region_name, scenario, input_folder,\n",
    "                 resolution=resolution,\n",
    "                 figsize=(12, 12),\n",
    "                 save_plot=plot_output_folder)\n",
    "\n",
    "    plot_timeseries(region_name, scenario, input_folder, figsize=(5, 9),\n",
    "                    save_plot=plot_output_folder)\n",
    "\n",
    "def plot_unavoidable_risk_for_all_scenarios(region_name, scenarios, input_folder,\n",
    "                                            output_folder):\n",
    "    plot_output_folder = os.path.join(output_folder, region_name)\n",
    "    mkdir(plot_output_folder)\n",
    "\n",
    "    plot_unavoidable_risk(region_name, scenarios, input_folder, figsize=(5, 15),\n",
    "                          save_plot=plot_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a72a2-4961-4039-94fc-2d0607e9b3d2",
   "metadata": {},
   "source": [
    "## testing in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5078198b-b309-4489-b169-8dc164903a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    test_output_folder = 'aggregated_result_plots_test'\n",
    "    mkdir(test_output_folder)\n",
    "\n",
    "    test_region = 'central_europe'\n",
    "    test_scenario = scenarios_mesmer[0]\n",
    "\n",
    "    plot_scenario_results_region(test_region, test_scenario,\n",
    "                                  input_folder, test_output_folder)\n",
    "\n",
    "    plot_unavoidable_risk_for_all_scenarios(test_region, scenarios_mesmer,\n",
    "                                            input_folder, test_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df29918-c8e2-4fe9-9ca8-e4afdd3115d6",
   "metadata": {},
   "source": [
    "## code for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978d28e9-19ee-434b-9c69-9be4c7d0f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_notebook:\n",
    "    # save results on cluster and copy at the end in run_slurm-file\n",
    "    working_dir_cluster = os.environ.get('OGGM_WORKDIR', None)\n",
    "\n",
    "    output_folder = os.path.join(working_dir_cluster,\n",
    "                                 output_folder)\n",
    "    mkdir(output_folder)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for region in region_structure_dict:\n",
    "        print(f'Start plotting {region}:')\n",
    "        print(f'    unavoidable risk ({time.time() - start_time:.1f} s)')\n",
    "        plot_unavoidable_risk_for_all_scenarios(region, scenarios_mesmer,\n",
    "                                                input_folder, output_folder)\n",
    "        for scenario in scenarios_mesmer:\n",
    "            print(f'    {scenario} plots ({time.time() - start_time:.1f} s)')\n",
    "            plot_scenario_results_region(region, scenario,\n",
    "                                         input_folder, output_folder,\n",
    "                                         add_map_plot=True,\n",
    "                                         resolution=1,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f33052-bc9b-4ab6-a050-cadf7e6e3835",
   "metadata": {},
   "source": [
    "# count files of each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb382048-a709-4c9d-ad64-e9af8753d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caucasus_and_middle_east 22 files\n",
      "central_asia 22 files\n",
      "central_europe 22 files\n",
      "east_asia 22 files\n",
      "greenland_periphery 22 files\n",
      "new_zealand 22 files\n",
      "northern_andes 22 files\n",
      "scandinavia_and_iceland 22 files\n",
      "southern_andes 22 files\n",
      "svalbard,_jan_mayen_and_russian_arctic 22 files\n",
      "western_canada_and_usa 22 files\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    nr_files_ref = None\n",
    "    for region in region_structure_dict:\n",
    "        path_region = os.path.join(output_folder,\n",
    "                                    region)\n",
    "        nr_files_region = len([file for file in os.listdir(path_region)\n",
    "                               if os.path.isfile(os.path.join(path_region,file))])\n",
    "        if nr_files_ref is None:\n",
    "            nr_files_ref = nr_files_region\n",
    "        elif nr_files_ref != nr_files_region:\n",
    "            print(f'!!!{region} {nr_files_region} files, reference {nr_files_ref}!!!')\n",
    "        else:\n",
    "            print(f'{region} {nr_files_region} files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b885e17-9871-41d7-9f23-8b88c03e0a62",
   "metadata": {},
   "source": [
    "# check output files for consistancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d63074-068f-4912-8af2-1716a994b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ref values arctic_canada\n",
      "Checking ref values caucasus_and_middle_east\n",
      "Checking ref values central_asia\n",
      "Checking ref values central_europe\n",
      "Checking ref values east_asia\n",
      "Checking ref values greenland_periphery\n",
      "Checking ref values new_zealand\n",
      "Checking ref values northern_andes\n",
      "Checking ref values scandinavia_and_iceland\n",
      "Checking ref values southern_andes\n",
      "Checking ref values svalbard,_jan_mayen_and_russian_arctic\n",
      "Checking ref values western_canada_and_usa\n",
      "Checking map sum 2020 for arctic_canada\n",
      "Checking map sum 2020 for caucasus_and_middle_east\n",
      "Checking map sum 2020 for central_asia\n",
      "Checking map sum 2020 for central_europe\n",
      "Checking map sum 2020 for east_asia\n",
      "Checking map sum 2020 for greenland_periphery\n",
      "Checking map sum 2020 for new_zealand\n",
      "Checking map sum 2020 for northern_andes\n",
      "Checking map sum 2020 for scandinavia_and_iceland\n",
      "Checking map sum 2020 for southern_andes\n",
      "Checking map sum 2020 for svalbard,_jan_mayen_and_russian_arctic\n",
      "Checking map sum 2020 for western_canada_and_usa\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    # same ref values for each scenario?\n",
    "    for region in region_structure_dict:\n",
    "        print(f'Checking ref values {region}')\n",
    "        ref_volume = None\n",
    "        ref_area = None\n",
    "        ref_runoff = None\n",
    "        for scenario in scenarios_mesmer:\n",
    "            with xr.open_dataset(\n",
    "                os.path.join(input_folder,\n",
    "                             region,\n",
    "                             f'{region}_{scenario}_timeseries.nc')) as ds_time:\n",
    "                if ref_volume is None:\n",
    "                    ref_volume = ds_time.volume.reference_2020_km3\n",
    "                else:\n",
    "                    if not np.isclose(ds_time.volume.reference_2020_km3,\n",
    "                                      ref_volume,\n",
    "                                      #rtol=0.01,\n",
    "                                      #atol=30\n",
    "                                     ):\n",
    "                        print(f'{region}/{scenario}: volume NOT close to reference '\n",
    "                              f'(given {ds_time.volume.reference_2020_km3:.1f}, '\n",
    "                              f'reference {ref_volume:.1f})')\n",
    "\n",
    "                if ref_area is None:\n",
    "                    ref_area = ds_time.area.reference_2020_km2\n",
    "                else:\n",
    "                    if not np.isclose(ds_time.area.reference_2020_km2,\n",
    "                                      ref_area,\n",
    "                                      #rtol=0.01,\n",
    "                                      #atol=80\n",
    "                                     ):\n",
    "                        print(f'{region}/{scenario}: area NOT close to reference '\n",
    "                              f'(given {ds_time.area.reference_2020_km2:.1f}, '\n",
    "                              f'reference {ref_area:.1f})')\n",
    "\n",
    "                if ref_runoff is None:\n",
    "                    ref_runoff = ds_time.runoff.reference_2000_2019_Mt_per_yer\n",
    "                else:\n",
    "                    if not np.isclose(ds_time.runoff.reference_2000_2019_Mt_per_yer,\n",
    "                                      ref_runoff,\n",
    "                                      #rtol=0.01,\n",
    "                                      #atol=80\n",
    "                                     ):\n",
    "                        print(f'{region}/{scenario}: runoff NOT close to reference '\n",
    "                              f'(given {ds_time.runoff.reference_2000_2019_Mt_per_yer:.1f}, '\n",
    "                              f'reference {ref_runoff:.1f})')\n",
    "\n",
    "    # are map values 2020 add up to 100%\n",
    "    for region in region_structure_dict:\n",
    "        print(f'Checking map sum 2020 for {region}')\n",
    "        for scenario in scenarios_mesmer:\n",
    "            with xr.open_dataset(\n",
    "                        os.path.join(input_folder,\n",
    "                                     region,\n",
    "                                     f'{region}_{scenario}_map.nc')) as ds_map:\n",
    "                for var in ['volume', 'area']:\n",
    "                    for quant in ds_map['quantile']:\n",
    "                        map_sum = ds_map.loc[{'time': 2020, 'quantile':quant}][var].sum().values\n",
    "                        if not np.isclose(map_sum, 100):\n",
    "                            if np.isclose(map_sum, 0):\n",
    "                                print(f'  {region} is 0 ({scenario}, {var}, {quant.values})')\n",
    "                            else:\n",
    "                                print(f'Map 2020 adds not up to 100, only {map_sum} '\n",
    "                                      f'({region}, {scenario}, {var}, {quant.values})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac69dc-5509-4e3f-93d4-6f8c584f1e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:oggm_env]",
   "language": "python",
   "name": "conda-env-oggm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
