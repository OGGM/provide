{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94ba39e4-5273-4430-94ec-d008b1594abe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ccb7ff-38d4-4547-8a13-826c7039f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16043214-d3e0-4740-86ac-7b9d1cb93dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go up until we are in the project base directory\n",
    "base_dir = os.getcwd()\n",
    "while base_dir.split('/')[-1] != 'provide':\n",
    "    base_dir = os.path.normpath(os.path.join(base_dir, '..'))\n",
    "\n",
    "# add paths for tools and data\n",
    "things_to_add = ['general_tools', 'aggregation_tools', 'general_data_for_aggregation']\n",
    "for thing in things_to_add:\n",
    "    sys.path.append(os.path.join(base_dir, thing))\n",
    "\n",
    "from general_tools import check_if_notebook, mkdir\n",
    "from oggm_result_filepath_and_realisations import scenarios_mesmer\n",
    "from aggregation_plots import plot_map, plot_timeseries, plot_unavoidable_risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0e9b0e3-4dd8-4343-b1dd-7273fb16169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to conditionally execute tests/debugging\n",
    "if check_if_notebook():\n",
    "    is_notebook = True\n",
    "else:\n",
    "    is_notebook = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be4688-17df-41ed-9de5-8b5fa0f26549",
   "metadata": {},
   "source": [
    "# define inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aab3070-22fe-4559-ad77-d0b1c13af553",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution_dir = 'total_data'\n",
    "input_folder = 'aggregated_data'\n",
    "output_folder = 'aggregated_result_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6c266b-726a-4915-abe6-c6b9a884e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_region_dict_outpath = os.path.join(base_dir, 'basins', resolution_dir)\n",
    "\n",
    "with open(os.path.join(preprocess_region_dict_outpath, \"preprocessed_region_grids.json\"), 'r') as f:\n",
    "    region_structure_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2571f61a-3090-4912-963d-d1f79c10d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_data_dir = os.path.join(base_dir, 'basins', 'data')\n",
    "regions_file = 'glacier_basins.shp'\n",
    "gdf_regions = gpd.read_file(os.path.join(regions_data_dir, regions_file))\n",
    "name_col_regions = 'full_name'\n",
    "\n",
    "gdf_regions[name_col_regions] = [re.sub(r'\\[.*?\\]|\\(.*?\\)', '', name).strip().lower().replace(' ', '_')\n",
    "                                 for name in gdf_regions['RIVER_BASI'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f387f-dc9a-4cb4-b1bc-34555790a38f",
   "metadata": {},
   "source": [
    "# plot for all regions and scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7038f3-df12-430d-99c9-27b5da38a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scenario_results_region(region_name, scenario, input_folder, output_folder,\n",
    "                                 add_map_plot=True, resolution=None,\n",
    "                                ):\n",
    "    plot_output_folder = os.path.join(output_folder, region_name)\n",
    "    mkdir(plot_output_folder)\n",
    "    region = gdf_regions[gdf_regions[name_col_regions] == region_name]\n",
    "\n",
    "    if add_map_plot:\n",
    "        plot_map(region, region_name, scenario, input_folder,\n",
    "                 resolution=resolution,\n",
    "                 figsize=(12, 12),\n",
    "                 save_plot=plot_output_folder)\n",
    "\n",
    "    plot_timeseries(region_name, scenario, input_folder,\n",
    "                    figsize=(5, 9),\n",
    "                    save_plot=plot_output_folder)\n",
    "\n",
    "def plot_unavoidable_risk_for_all_scenarios(region_name, scenarios, input_folder,\n",
    "                                            output_folder):\n",
    "    plot_output_folder = os.path.join(output_folder, region_name)\n",
    "    mkdir(plot_output_folder)\n",
    "\n",
    "    plot_unavoidable_risk(region_name, scenarios, input_folder, figsize=(5, 15),\n",
    "                          save_plot=plot_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a72a2-4961-4039-94fc-2d0607e9b3d2",
   "metadata": {},
   "source": [
    "## testing in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5078198b-b309-4489-b169-8dc164903a9d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/www/pschmitt/provide/aggregate_data/github/provide/basins/total_data/aggregated_data/ISL/ISL_CurPol_map.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/home/www/pschmitt/provide/aggregate_data/github/provide/basins/total_data/aggregated_data/ISL/ISL_CurPol_map.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '8fbc3afa-7887-4b30-a191-207fcbe6ce08']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m test_region \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISL\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m test_scenario \u001b[38;5;241m=\u001b[39m scenarios_mesmer[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[43mplot_scenario_results_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_region\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_scenario\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                              \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_output_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m plot_unavoidable_risk_for_all_scenarios(test_region, scenarios_mesmer,\n\u001b[1;32m     12\u001b[0m                                         input_folder, test_output_folder)\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mplot_scenario_results_region\u001b[0;34m(region_name, scenario, input_folder, output_folder, add_map_plot, resolution)\u001b[0m\n\u001b[1;32m      6\u001b[0m region \u001b[38;5;241m=\u001b[39m gdf_regions[gdf_regions[name_col_regions] \u001b[38;5;241m==\u001b[39m region_name]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_map_plot:\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mplot_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenario\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m             \u001b[49m\u001b[43msave_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_output_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m plot_timeseries(region_name, scenario, input_folder,\n\u001b[1;32m     15\u001b[0m                 figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m9\u001b[39m),\n\u001b[1;32m     16\u001b[0m                 save_plot\u001b[38;5;241m=\u001b[39mplot_output_folder)\n",
      "File \u001b[0;32m/home/www/pschmitt/provide/aggregate_data/github/provide/aggregation_tools/aggregation_plots.py:65\u001b[0m, in \u001b[0;36mplot_map\u001b[0;34m(target, target_name, scenario, input_dir, resolution, figsize, save_plot)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m transform(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: _adjust_lon(x, y), geometry)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscenario\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_map.nc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m ds:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# if we have negative lon we convert to 0-360 and not crossing 0 degrees\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(np\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[1;32m     71\u001b[0m         ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mwhere(ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     72\u001b[0m                              ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m360\u001b[39m,\n\u001b[1;32m     73\u001b[0m                              ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/api.py:570\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[1;32m    559\u001b[0m     decode_cf,\n\u001b[1;32m    560\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    566\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m    567\u001b[0m )\n\u001b[1;32m    569\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 570\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_variables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdecoders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    577\u001b[0m     backend_ds,\n\u001b[1;32m    578\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    589\u001b[0m )\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:602\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    583\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    599\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m    601\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[0;32m--> 602\u001b[0m     store \u001b[38;5;241m=\u001b[39m \u001b[43mNetCDF4DataStore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclobber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclobber\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdiskless\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiskless\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:400\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    394\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    395\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    396\u001b[0m )\n\u001b[1;32m    397\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    398\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    399\u001b[0m )\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:347\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 347\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:409\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:403\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/mambaforge/envs/oggm_env/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2469\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/www/pschmitt/provide/aggregate_data/github/provide/basins/total_data/aggregated_data/ISL/ISL_CurPol_map.nc'"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    test_output_folder = 'aggregated_result_plots_test'\n",
    "    mkdir(test_output_folder)\n",
    "\n",
    "    test_region = 'ISL'\n",
    "    test_scenario = scenarios_mesmer[0]\n",
    "\n",
    "    plot_scenario_results_region(test_region, test_scenario,\n",
    "                                  input_folder, test_output_folder)\n",
    "\n",
    "    plot_unavoidable_risk_for_all_scenarios(test_region, scenarios_mesmer,\n",
    "                                            input_folder, test_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df29918-c8e2-4fe9-9ca8-e4afdd3115d6",
   "metadata": {},
   "source": [
    "## code for cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "978d28e9-19ee-434b-9c69-9be4c7d0f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_notebook:\n",
    "    # save results on cluster and copy at the end in run_slurm-file\n",
    "    working_dir_cluster = os.environ.get('OGGM_WORKDIR', None)\n",
    "\n",
    "    output_folder = os.path.join(working_dir_cluster,\n",
    "                                 output_folder)\n",
    "    mkdir(output_folder)\n",
    "\n",
    "    start_time = time.time()\n",
    "    for region in region_structure_dict:\n",
    "        print(f'Start plotting {region}:')\n",
    "        print(f'    unavoidable risk ({time.time() - start_time:.1f} s)')\n",
    "        plot_unavoidable_risk_for_all_scenarios(region, scenarios_mesmer,\n",
    "                                                input_folder, output_folder)\n",
    "        for scenario in scenarios_mesmer:\n",
    "            print(f'    {scenario} plots ({time.time() - start_time:.1f} s)')\n",
    "            plot_scenario_results_region(region, scenario,\n",
    "                                         input_folder, output_folder,\n",
    "                                         add_map_plot=True,\n",
    "                                         resolution=1,\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f33052-bc9b-4ab6-a050-cadf7e6e3835",
   "metadata": {},
   "source": [
    "# count files of each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb382048-a709-4c9d-ad64-e9af8753d806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ob 22 files\n",
      "brahmaputra 22 files\n",
      "ganges 22 files\n",
      "indus 22 files\n",
      "irrawaddy 22 files\n",
      "salween 22 files\n",
      "kamchatka 22 files\n",
      "mekong 22 files\n",
      "yangtze 22 files\n",
      "yellow_river 22 files\n",
      "aral_sea 22 files\n",
      "chuy 22 files\n",
      "har_us_nuur 22 files\n",
      "lake_balkhash 22 files\n",
      "talas 22 files\n",
      "tarim_he 22 files\n",
      "uvs_nuur 22 files\n",
      "ysyk-kol 22 files\n",
      "amazon 22 files\n",
      "chico 22 files\n",
      "colorado 22 files\n",
      "magdalena 22 files\n",
      "negro 22 files\n",
      "santa_cruz 22 files\n",
      "aisen 22 files\n",
      "azopardo 22 files\n",
      "baker 22 files\n",
      "biobio 22 files\n",
      "cisnes 22 files\n",
      "copiapo 22 files\n",
      "huasco 22 files\n",
      "majes 22 files\n",
      "ocona 22 files\n",
      "palena 22 files\n",
      "pascua 22 files\n",
      "puelo 22 files\n",
      "rapel 22 files\n",
      "santa 22 files\n",
      "serrano 22 files\n",
      "valdivia 22 files\n",
      "yelcho 22 files\n",
      "titicaca 22 files\n",
      "colville 22 files\n",
      "mackenzie 22 files\n",
      "nelson 22 files\n",
      "alsek 22 files\n",
      "columbia 22 files\n",
      "copper 22 files\n",
      "fraser 22 files\n",
      "kuskokwim 22 files\n",
      "nass 22 files\n",
      "nushagak 22 files\n",
      "skagit 22 files\n",
      "skeena 22 files\n",
      "stikine 22 files\n",
      "susitna 22 files\n",
      "taku 22 files\n",
      "yukon 22 files\n",
      "clutha 22 files\n",
      "jokulsa_a_fjollum 22 files\n",
      "lagarfljot 22 files\n",
      "svarta 22 files\n",
      "danube 22 files\n",
      "dramselva 22 files\n",
      "glomaa 22 files\n",
      "kalixalven 22 files\n",
      "kuban 22 files\n",
      "lulealven 22 files\n",
      "olfusa 22 files\n",
      "po 22 files\n",
      "rhine 22 files\n",
      "rhone 22 files\n",
      "thjorsa 22 files\n",
      "tornealven 22 files\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    nr_files_ref = None\n",
    "    for region in region_structure_dict:\n",
    "        path_region = os.path.join(output_folder,\n",
    "                                    region)\n",
    "        nr_files_region = len([file for file in os.listdir(path_region)\n",
    "                               if os.path.isfile(os.path.join(path_region,file))])\n",
    "        if nr_files_ref is None:\n",
    "            nr_files_ref = nr_files_region\n",
    "        elif nr_files_ref != nr_files_region:\n",
    "            print(f'!!!{region} {nr_files_region} files, reference {nr_files_ref}!!!')\n",
    "        else:\n",
    "            print(f'{region} {nr_files_region} files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b885e17-9871-41d7-9f23-8b88c03e0a62",
   "metadata": {},
   "source": [
    "# check output files for consistancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d63074-068f-4912-8af2-1716a994b935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ref values indigirka\n",
      "Checking ref values ob\n",
      "Checking ref values brahmaputra\n",
      "Checking ref values ganges\n",
      "Checking ref values indus\n",
      "Checking ref values irrawaddy\n",
      "Checking ref values salween\n",
      "Checking ref values kamchatka\n",
      "Checking ref values mekong\n",
      "Checking ref values yangtze\n",
      "Checking ref values yellow_river\n",
      "Checking ref values aral_sea\n",
      "Checking ref values chuy\n",
      "Checking ref values har_us_nuur\n",
      "Checking ref values lake_balkhash\n",
      "Checking ref values talas\n",
      "Checking ref values tarim_he\n",
      "Checking ref values uvs_nuur\n",
      "Checking ref values ysyk-kol\n",
      "Checking ref values amazon\n",
      "Checking ref values chico\n",
      "Checking ref values colorado\n",
      "Checking ref values magdalena\n",
      "Checking ref values negro\n",
      "Checking ref values santa_cruz\n",
      "Checking ref values aisen\n",
      "Checking ref values azopardo\n",
      "Checking ref values baker\n",
      "Checking ref values biobio\n",
      "Checking ref values cisnes\n",
      "Checking ref values copiapo\n",
      "Checking ref values huasco\n",
      "Checking ref values majes\n",
      "Checking ref values ocona\n",
      "Checking ref values palena\n",
      "Checking ref values pascua\n",
      "Checking ref values puelo\n",
      "Checking ref values rapel\n",
      "Checking ref values santa\n",
      "Checking ref values serrano\n",
      "Checking ref values valdivia\n",
      "Checking ref values yelcho\n",
      "Checking ref values titicaca\n",
      "Checking ref values colville\n",
      "Checking ref values mackenzie\n",
      "Checking ref values nelson\n",
      "Checking ref values alsek\n",
      "Checking ref values columbia\n",
      "Checking ref values copper\n",
      "Checking ref values fraser\n",
      "Checking ref values kuskokwim\n",
      "Checking ref values nass\n",
      "Checking ref values nushagak\n",
      "Checking ref values skagit\n",
      "Checking ref values skeena\n",
      "Checking ref values stikine\n",
      "Checking ref values susitna\n",
      "Checking ref values taku\n",
      "Checking ref values yukon\n",
      "Checking ref values clutha\n",
      "Checking ref values jokulsa_a_fjollum\n",
      "Checking ref values lagarfljot\n",
      "Checking ref values svarta\n",
      "Checking ref values danube\n",
      "Checking ref values dramselva\n",
      "Checking ref values glomaa\n",
      "Checking ref values kalixalven\n",
      "Checking ref values kuban\n",
      "Checking ref values lulealven\n",
      "Checking ref values olfusa\n",
      "Checking ref values po\n",
      "Checking ref values rhine\n",
      "Checking ref values rhone\n",
      "Checking ref values thjorsa\n",
      "Checking ref values tornealven\n",
      "Checking map sum 2020 for indigirka\n",
      "Checking map sum 2020 for ob\n",
      "Checking map sum 2020 for brahmaputra\n",
      "Checking map sum 2020 for ganges\n",
      "Checking map sum 2020 for indus\n",
      "Checking map sum 2020 for irrawaddy\n",
      "Checking map sum 2020 for salween\n",
      "Checking map sum 2020 for kamchatka\n",
      "Checking map sum 2020 for mekong\n",
      "Checking map sum 2020 for yangtze\n",
      "Checking map sum 2020 for yellow_river\n",
      "Checking map sum 2020 for aral_sea\n",
      "Checking map sum 2020 for chuy\n",
      "Checking map sum 2020 for har_us_nuur\n",
      "Checking map sum 2020 for lake_balkhash\n",
      "Checking map sum 2020 for talas\n",
      "Checking map sum 2020 for tarim_he\n",
      "Checking map sum 2020 for uvs_nuur\n",
      "Checking map sum 2020 for ysyk-kol\n",
      "Checking map sum 2020 for amazon\n",
      "Checking map sum 2020 for chico\n",
      "Checking map sum 2020 for colorado\n",
      "Checking map sum 2020 for magdalena\n",
      "Checking map sum 2020 for negro\n",
      "Checking map sum 2020 for santa_cruz\n",
      "Checking map sum 2020 for aisen\n",
      "Checking map sum 2020 for azopardo\n",
      "Checking map sum 2020 for baker\n",
      "Checking map sum 2020 for biobio\n",
      "Checking map sum 2020 for cisnes\n",
      "Checking map sum 2020 for copiapo\n",
      "Checking map sum 2020 for huasco\n",
      "Checking map sum 2020 for majes\n",
      "Checking map sum 2020 for ocona\n",
      "Checking map sum 2020 for palena\n",
      "Checking map sum 2020 for pascua\n",
      "Checking map sum 2020 for puelo\n",
      "Checking map sum 2020 for rapel\n",
      "Checking map sum 2020 for santa\n",
      "Checking map sum 2020 for serrano\n",
      "Checking map sum 2020 for valdivia\n",
      "Checking map sum 2020 for yelcho\n",
      "Checking map sum 2020 for titicaca\n",
      "Checking map sum 2020 for colville\n",
      "Checking map sum 2020 for mackenzie\n",
      "Checking map sum 2020 for nelson\n",
      "Checking map sum 2020 for alsek\n",
      "Checking map sum 2020 for columbia\n",
      "Checking map sum 2020 for copper\n",
      "Checking map sum 2020 for fraser\n",
      "Checking map sum 2020 for kuskokwim\n",
      "Checking map sum 2020 for nass\n",
      "Checking map sum 2020 for nushagak\n",
      "Checking map sum 2020 for skagit\n",
      "Checking map sum 2020 for skeena\n",
      "Checking map sum 2020 for stikine\n",
      "Checking map sum 2020 for susitna\n",
      "Checking map sum 2020 for taku\n",
      "Checking map sum 2020 for yukon\n",
      "Checking map sum 2020 for clutha\n",
      "Checking map sum 2020 for jokulsa_a_fjollum\n",
      "Checking map sum 2020 for lagarfljot\n",
      "Checking map sum 2020 for svarta\n",
      "Checking map sum 2020 for danube\n",
      "Checking map sum 2020 for dramselva\n",
      "Checking map sum 2020 for glomaa\n",
      "Checking map sum 2020 for kalixalven\n",
      "Checking map sum 2020 for kuban\n",
      "Checking map sum 2020 for lulealven\n",
      "Checking map sum 2020 for olfusa\n",
      "Checking map sum 2020 for po\n",
      "Checking map sum 2020 for rhine\n",
      "Checking map sum 2020 for rhone\n",
      "Checking map sum 2020 for thjorsa\n",
      "Checking map sum 2020 for tornealven\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    # same ref values for each scenario?\n",
    "    for region in region_structure_dict:\n",
    "        print(f'Checking ref values {region}')\n",
    "        ref_volume = None\n",
    "        ref_area = None\n",
    "        ref_runoff = None\n",
    "        for scenario in scenarios_mesmer:\n",
    "            with xr.open_dataset(\n",
    "                os.path.join(input_folder,\n",
    "                             region,\n",
    "                             f'{region}_{scenario}_timeseries.nc')) as ds_time:\n",
    "                if ref_volume is None:\n",
    "                    ref_volume = ds_time.volume.reference_2020_km3\n",
    "                else:\n",
    "                    if not np.isclose(ds_time.volume.reference_2020_km3,\n",
    "                                      ref_volume,\n",
    "                                      #rtol=0.01,\n",
    "                                      #atol=30\n",
    "                                     ):\n",
    "                        print(f'{region}/{scenario}: volume NOT close to reference '\n",
    "                              f'(given {ds_time.volume.reference_2020_km3:.1f}, '\n",
    "                              f'reference {ref_volume:.1f})')\n",
    "\n",
    "                if ref_area is None:\n",
    "                    ref_area = ds_time.area.reference_2020_km2\n",
    "                else:\n",
    "                    if not np.isclose(ds_time.area.reference_2020_km2,\n",
    "                                      ref_area,\n",
    "                                      #rtol=0.01,\n",
    "                                      #atol=80\n",
    "                                     ):\n",
    "                        print(f'{region}/{scenario}: area NOT close to reference '\n",
    "                              f'(given {ds_time.area.reference_2020_km2:.1f}, '\n",
    "                              f'reference {ref_area:.1f})')\n",
    "\n",
    "                if ref_runoff is None:\n",
    "                    ref_runoff = ds_time.runoff.reference_2000_2019_Mt_per_yer\n",
    "                else:\n",
    "                    if not np.isclose(ds_time.runoff.reference_2000_2019_Mt_per_yer,\n",
    "                                      ref_runoff,\n",
    "                                      #rtol=0.01,\n",
    "                                      #atol=80\n",
    "                                     ):\n",
    "                        print(f'{region}/{scenario}: runoff NOT close to reference '\n",
    "                              f'(given {ds_time.runoff.reference_2000_2019_Mt_per_yer:.1f}, '\n",
    "                              f'reference {ref_runoff:.1f})')\n",
    "\n",
    "    # are map values 2020 add up to 100%\n",
    "    for region in region_structure_dict:\n",
    "        print(f'Checking map sum 2020 for {region}')\n",
    "        for scenario in scenarios_mesmer:\n",
    "            with xr.open_dataset(\n",
    "                        os.path.join(input_folder,\n",
    "                                     region,\n",
    "                                     f'{region}_{scenario}_map.nc')) as ds_map:\n",
    "                for var in ['volume', 'area']:\n",
    "                    for quant in ds_map['quantile']:\n",
    "                        map_sum = ds_map.loc[{'time': 2020, 'quantile':quant}][var].sum().values\n",
    "                        if not np.isclose(map_sum, 100):\n",
    "                            if np.isclose(map_sum, 0):\n",
    "                                print(f'  {region} is 0 ({scenario}, {var}, {quant.values})')\n",
    "                            else:\n",
    "                                print(f'Map 2020 adds not up to 100, only {map_sum} '\n",
    "                                      f'({region}, {scenario}, {var}, {quant.values})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90190cc1-3d37-42e4-89f7-8a801dce0cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:oggm_env]",
   "language": "python",
   "name": "conda-env-oggm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
