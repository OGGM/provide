{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dfade2-f558-40ab-9fe6-12f9db114287",
   "metadata": {},
   "source": [
    "Create a list which points each rgi_id to a provide region and a batch file:\n",
    "  - e.g. P01/0_500\n",
    "    - provide region 1\n",
    "    - batch 0_500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fdf29-a8d4-4838-94b5-6f3fe4b0905a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10da327-92ad-478b-a493-d87e0317cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "from oggm import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbaaedcf-fb6c-466c-9d82-1272af8fda5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "# go up until we are in the project base directory\n",
    "path_to_add = base_path\n",
    "while path_to_add.split('/')[-1] != 'provide':\n",
    "    path_to_add = os.path.normpath(os.path.join(path_to_add, '..'))\n",
    "\n",
    "# add paths for tools and data\n",
    "things_to_add = ['general_tools', 'aggregation_tools', 'general_data_for_aggregation']\n",
    "for thing in things_to_add:\n",
    "    sys.path.append(os.path.join(path_to_add, thing))\n",
    "\n",
    "# import stuff we need\n",
    "from general_tools import check_if_notebook\n",
    "from oggm_result_filepath_and_realisations import (gcms_mesmer, quantiles_mesmer,\n",
    "    scenarios_mesmer, oggm_result_dir, provide_regions, raw_oggm_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37fad890-2983-4773-be00-162d42e3bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_general_data = os.path.join(path_to_add, 'general_data_for_aggregation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b176e817-99a3-48e4-9354-96edf4e94093",
   "metadata": {},
   "source": [
    "# Template for resulting conversion list (drop connectivity=2, drop RGI19, only common running glaciers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31089abf-17bd-4f4f-874a-95abf329a8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frgi = utils.file_downloader('https://cluster.klima.uni-bremen.de/~oggm/rgi/rgi62_stats.h5')\n",
    "df_rgi = pd.read_hdf(frgi, index_col=0)\n",
    "rgi_ids_connect_2 = list(df_rgi[df_rgi.Connect != 2].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2348ae8b-7ae5-414b-ad9d-9ef2e86ce6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template structure\n",
    "fp_rgi_prov_region = \"rgi_ids_to_provide_region.json\"\n",
    "with open(os.path.join(output_dir_general_data, fp_rgi_prov_region), 'r') as f:\n",
    "    dict_rgis_to_preg = json.load(f)\n",
    "\n",
    "# open common running glaciers\n",
    "fp_common_running = \"commonly_running_glaciers.json\"\n",
    "with open(os.path.join(output_dir_general_data, fp_common_running), 'r') as f:\n",
    "    list_common_running = json.load(f)\n",
    "\n",
    "all_rgi_ids = list(dict_rgis_to_preg)\n",
    "\n",
    "# drop connectivity level 2\n",
    "all_rgi_ids = list(set(all_rgi_ids) & set(rgi_ids_connect_2))\n",
    "\n",
    "# drop rgi_region 19\n",
    "all_rgi_ids = [rgi_id for rgi_id in all_rgi_ids if rgi_id[6:8] != 19]\n",
    "\n",
    "# keep only common running glaciers\n",
    "all_rgi_ids = list(set(all_rgi_ids) & set(list_common_running))\n",
    "\n",
    "# create template structure and set everything to None\n",
    "dict_rgis_to_batch = {}\n",
    "for rgi_id in all_rgi_ids:\n",
    "    dict_rgis_to_batch[rgi_id] = None\n",
    "\n",
    "assert all(value is None for value in dict_rgis_to_batch.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27aa1aa8-fc13-4966-b975-8a47ae4d9fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206685"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_rgis_to_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cbd50-d286-45d9-9c07-ff1258ef25c9",
   "metadata": {},
   "source": [
    "# define region and batch per rgi_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0f93665-fdea-4ed6-9e01-9c2abfc5a68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region P01\n",
      "Region P02\n",
      "Region P03\n",
      "Region P04\n",
      "Region P05\n",
      "Region P06\n",
      "Region P07\n",
      "Region P08\n",
      "Region P09\n",
      "Region P10\n",
      "Region P11\n",
      "Region P12\n",
      "Time needed: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "# use one realisation for checking where glaciers are located\n",
    "start_time = time.time()\n",
    "dummy_file = raw_oggm_output_file.format(scenarios_mesmer[0],\n",
    "                                         gcms_mesmer[0],\n",
    "                                         quantiles_mesmer[0])\n",
    "for region in provide_regions:\n",
    "    print(f'Region {region}')\n",
    "    for file_path in glob.glob(os.path.join(oggm_result_dir, region, dummy_file)):\n",
    "        batch_nr = file_path.split('_')[-2] + '_' + file_path.split('_')[-1].split('.')[0]\n",
    "\n",
    "        with xr.open_dataset(file_path) as ds:\n",
    "            rgi_ids = ds.rgi_id.values\n",
    "            # only keep rgi_ids which we need (e.g. only common running)\n",
    "            rgi_ids = list(set(rgi_ids) & set(list(dict_rgis_to_batch)))\n",
    "\n",
    "            # before updating check if all values are still None\n",
    "            if not all(dict_rgis_to_batch[rgi_id] is None for rgi_id in rgi_ids):\n",
    "                assigned_rgi_ids = []\n",
    "                assigned_batch = []\n",
    "                for rgi_id in rgi_ids:\n",
    "                    if dict_rgis_to_batch[rgi_id] is not None:\n",
    "                        assigned_rgi_ids.append(rgi_id)\n",
    "                        assigned_batch.append(dict_rgis_to_batch[rgi_id])\n",
    "                raise AttributeError(f'some rgi_ids ({assigned_rgi_ids}) where already assigned '\n",
    "                                     f'to a different file ({assigned_batch})! '\n",
    "                                     f'Current batch: {region}/{batch_nr}')\n",
    "            dict_rgis_to_batch.update({rgi_id: f'{region}/{batch_nr}' for rgi_id in rgi_ids})\n",
    "\n",
    "# at the end all should be assined\n",
    "assert all(value is not None for value in dict_rgis_to_batch.values())\n",
    "\n",
    "# save conversion list as json\n",
    "with open(os.path.join(output_dir_general_data,\n",
    "                       \"rgi_ids_to_result_batch.json\"), \"w\") as outfile: \n",
    "    json.dump(dict_rgis_to_batch, outfile)\n",
    "\n",
    "print(f'Time needed: {time.time() - start_time:.1f} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:oggm_env]",
   "language": "python",
   "name": "conda-env-oggm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
