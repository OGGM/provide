{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d8cb07-d86e-4559-8317-4c5fb34e9600",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd623e-49db-49c7-b585-f93427d8e4a3",
   "metadata": {},
   "source": [
    "## general packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33178682-1199-4531-a933-a7e730703302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0c8e4-db2b-4e18-853f-12674f310060",
   "metadata": {},
   "source": [
    "## project tools and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72a50139-f7fc-450e-acf1-a51e0ec24148",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "\n",
    "# go up until we are in the project base directory\n",
    "path_to_add = base_path\n",
    "while path_to_add.split('/')[-1] != 'provide':\n",
    "    path_to_add = os.path.normpath(os.path.join(path_to_add, '..'))\n",
    "\n",
    "# add paths for tools and data\n",
    "things_to_add = ['general_tools', 'aggregation_tools', 'general_data_for_aggregation']\n",
    "for thing in things_to_add:\n",
    "    sys.path.append(os.path.join(path_to_add, thing))\n",
    "\n",
    "# import stuff we need\n",
    "from general_tools import check_if_notebook\n",
    "from oggm_result_filepath_and_realisations import (gcms_mesmer, quantiles_mesmer,\n",
    "    scenarios_mesmer, oggm_result_dir, provide_regions, raw_oggm_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de500d3-ed81-49ab-8a8d-ea729d048de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to conditionally execute tests/debugging\n",
    "if check_if_notebook():\n",
    "    is_notebook = True\n",
    "else:\n",
    "    is_notebook = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e07c1e2-bd58-4666-8a6e-96f460be9a10",
   "metadata": {},
   "source": [
    "# define directories for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20f9be5-52c3-4aeb-a2c3-521c63cb131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir_region = os.path.join(base_path, 'common_running_glaciers_slurm')\n",
    "output_dir_all = os.path.join(path_to_add, 'general_data_for_aggregation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da99e67-4a60-414b-9c83-de35709213b9",
   "metadata": {},
   "source": [
    "# Acutal work is done here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfd9f3b-7891-4073-b2b8-93e04c507e2a",
   "metadata": {},
   "source": [
    "## help functions for getting batched-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8395f1c4-3414-4a79-9bab-54017146f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches_of_region(region):\n",
    "    files = glob.glob(os.path.join(oggm_result_dir, region, raw_oggm_output_file))\n",
    "    batches = []\n",
    "    for file in files:\n",
    "        parts = os.path.basename(file).split('_')\n",
    "        batches.append(f\"{parts[-2]}_{parts[-1].replace('.nc','')}\")\n",
    "    return list(np.unique(batches))\n",
    "\n",
    "\n",
    "def get_filename_with_batch(batch):\n",
    "    return raw_oggm_output_file[::-1].replace('*', batch[::-1], 1)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81557712-6612-4e1f-b747-3c698e752173",
   "metadata": {},
   "source": [
    "## open multiple files, extract commonly running glaciers and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf1a283-63ed-48a3-acb9-f0a465ea0a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    \"\"\"\n",
    "    Preprocess function to extract model, scenario, and quantile from the filename\n",
    "    and add them as coordinates to the dataset.\n",
    "    \"\"\"\n",
    "    # only need volume here\n",
    "    ds = ds[['volume']]\n",
    "\n",
    "    # Extract model, scenario, and quantile from the filename\n",
    "    filename = ds.encoding['source']\n",
    "    parts = os.path.basename(filename).split('_')\n",
    "    scenario = parts[5]\n",
    "    gcm = parts[6]\n",
    "    quantile = float(parts[7].replace('q', ''))\n",
    "    ds = ds.expand_dims({'gcm': [gcm], 'scenario': [scenario], 'quantile': [quantile]})\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13a54084-06ca-4307-9907-b65f46a293be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_notebook:\n",
    "    # slurm comment: sbatch --array=1-12 run_slurm_common_running_glaciers.sh\n",
    "    \n",
    "    # extract provide region from execution\n",
    "    region = os.environ.get('PROVIDE_REG', None)\n",
    "    if region is None:\n",
    "        raise ValueError('Need a Provide region to start!')\n",
    "\n",
    "    # for all gcms\n",
    "    start_time = time.time()\n",
    "    commonly_running_glaciers_all = []\n",
    "    #for region in provide_regions:\n",
    "    print(f'Start region {region} for all.')\n",
    "    region_batches = get_batches_of_region(region)\n",
    "\n",
    "    for batch in region_batches:\n",
    "        print(f'batch {batch}')\n",
    "        files = glob.glob(\n",
    "            os.path.join(oggm_result_dir,\n",
    "                         region,\n",
    "                         get_filename_with_batch(batch)\n",
    "                        )\n",
    "        )\n",
    "        \n",
    "        combined_ds = xr.open_mfdataset(files,\n",
    "                                        preprocess=preprocess,\n",
    "                                        combine='by_coords',\n",
    "                                        parallel=False)\n",
    "\n",
    "        commonly_running_glaciers_all.extend(\n",
    "            list(combined_ds.volume.dropna(\n",
    "                dim='rgi_id', how='any').rgi_id.values)\n",
    "        )\n",
    "        combined_ds.close()\n",
    "\n",
    "    with open(os.path.join(output_dir_region,\n",
    "                           f\"commonly_running_glaciers_all_{region}.json\"), \"w\") as outfile: \n",
    "        json.dump(commonly_running_glaciers_all, outfile)\n",
    "\n",
    "    print(f'Time needed for all gcms {time.time() - start_time:.1f} s')\n",
    "    print('')\n",
    "\n",
    "    # excluding IPSL-CM6A-LR\n",
    "    start_time = time.time()\n",
    "    commonly_running_glaciers_without_IPSL = []\n",
    "    #for region in provide_regions:\n",
    "    print(f'Start region {region} without IPSL.')\n",
    "    region_batches = get_batches_of_region(region)\n",
    "    for batch in region_batches:\n",
    "        print(f'batch {batch}')\n",
    "        files = glob.glob(\n",
    "            os.path.join(oggm_result_dir,\n",
    "                         region,\n",
    "                         get_filename_with_batch(batch)\n",
    "                        )\n",
    "        )\n",
    "        files = [file for file in files if 'IPSL-CM6A-LR' not in file]\n",
    "        combined_ds = xr.open_mfdataset(files,\n",
    "                                        preprocess=preprocess,\n",
    "                                        combine='by_coords',\n",
    "                                        parallel=False)\n",
    "        commonly_running_glaciers_without_IPSL.extend(\n",
    "            list(combined_ds.volume.dropna(\n",
    "                dim='rgi_id', how='any').rgi_id.values)\n",
    "        )\n",
    "        combined_ds.close()\n",
    "    with open(os.path.join(output_dir_region,\n",
    "                           f\"commonly_running_glaciers_without_IPSL_{region}.json\"), \"w\") as outfile: \n",
    "        json.dump(commonly_running_glaciers_without_IPSL, outfile)\n",
    "    print(f'Time needed without IPSL {time.time() - start_time:.1f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b0a850-c891-4085-8e56-74c37bc765da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed 12.1 s\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "    test_region = provide_regions[7]\n",
    "    files = glob.glob(os.path.join(oggm_result_dir, test_region, raw_oggm_output_file))\n",
    "    test_gcms = [gcms_mesmer[0], gcms_mesmer[1]]\n",
    "    test_scenarios_mesmer = [scenarios_mesmer[0], scenarios_mesmer[1]]\n",
    "    # Function to filter long strings\n",
    "    def filter_long_strings(long_strings, list1, list2):\n",
    "        # List to store the result\n",
    "        filtered_strings = []\n",
    "        \n",
    "        # Iterate through each long string\n",
    "        for long_string in long_strings:\n",
    "            # Check if the long string contains at least one string from each list\n",
    "            if any(short_string in long_string for short_string in list1) and \\\n",
    "               any(short_string in long_string for short_string in list2):\n",
    "                # If both conditions are met, add the long string to the result list\n",
    "                filtered_strings.append(long_string)\n",
    "        \n",
    "        return filtered_strings\n",
    "    test_files = filter_long_strings(files, test_gcms, test_scenarios_mesmer)\n",
    "    start_time = time.time()\n",
    "    combined_ds = xr.open_mfdataset(test_files,\n",
    "                                    preprocess=preprocess,\n",
    "                                    combine='by_coords',\n",
    "                                    parallel=False)\n",
    "    print(f'Time needed {time.time() - start_time:.1f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefcde6d-6fef-447a-abaf-6bf2623627ec",
   "metadata": {},
   "source": [
    "# Merge all list into single list after cluster run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "550ff280-3125-4094-b065-f37870278653",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    common_running_list_dir = output_dir_region\n",
    "    raw_filename = 'commonly_running_glaciers_all_{}.json'\n",
    "\n",
    "    all_common_running_glaciers = []\n",
    "    for region in provide_regions:\n",
    "        with open(os.path.join(common_running_list_dir,\n",
    "                               raw_filename.format(region)), 'r') as f:\n",
    "            all_common_running_glaciers.extend(json.load(f))\n",
    "\n",
    "    with open(os.path.join(output_dir_all,\n",
    "                           f\"commonly_running_glaciers.json\"), \"w\") as outfile: \n",
    "        json.dump(all_common_running_glaciers, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae2048-6520-4039-b528-86a4c1fad41e",
   "metadata": {},
   "source": [
    "# Look at results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea78a802-8764-4230-95d8-7dc9c70e6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_notebook:\n",
    "    from oggm import utils\n",
    "    import pandas as pd\n",
    "\n",
    "    frgi = utils.file_downloader('https://cluster.klima.uni-bremen.de/~oggm/rgi/rgi62_stats.h5')\n",
    "    df_rgi = pd.read_hdf(frgi, index_col=0)\n",
    "\n",
    "    fp_rgi_prov_region = 'rgi_ids_per_provide_region.json'\n",
    "    with open(os.path.join(output_dir_all, fp_rgi_prov_region), 'r') as f:\n",
    "        dict_rgis_preg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7154d6f2-e9cd-43b5-a6c6-4580b8ca9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region P01:\n",
      "  ALL nr RGI-IDS: 45942\n",
      " CAll nr RGI-IDS: 45249\n",
      " IPSL nr RGI-IDS: 45255\n",
      "     CALL - IPSL: -6\n",
      "      ALL - CALL: 693\n",
      "        ALL area: 101231.1 km2, 100.0 %\n",
      "       CAll area: 101193.1 km2, 99.962 %\n",
      "       IPSL area: 101194.4 km2, 99.964 %\n",
      "     CALL - IPSL: -1.3 km2\n",
      "      ALL - CALL: 38.0 km2\n",
      "Region P02:\n",
      "  ALL nr RGI-IDS: 11971\n",
      " CAll nr RGI-IDS: 11847\n",
      " IPSL nr RGI-IDS: 11847\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 124\n",
      "        ALL area: 145998.9 km2, 100.0 %\n",
      "       CAll area: 145951.8 km2, 99.968 %\n",
      "       IPSL area: 145951.8 km2, 99.968 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 47.1 km2\n",
      "Region P03:\n",
      "  ALL nr RGI-IDS: 19306\n",
      " CAll nr RGI-IDS: 17220\n",
      " IPSL nr RGI-IDS: 17232\n",
      "     CALL - IPSL: -12\n",
      "      ALL - CALL: 2086\n",
      "        ALL area: 89717.1 km2, 100.0 %\n",
      "       CAll area: 88040.0 km2, 98.131 %\n",
      "       IPSL area: 88042.5 km2, 98.134 %\n",
      "     CALL - IPSL: -2.5 km2\n",
      "      ALL - CALL: 1677.0 km2\n",
      "Region P04:\n",
      "  ALL nr RGI-IDS: 4033\n",
      " CAll nr RGI-IDS: 3939\n",
      " IPSL nr RGI-IDS: 3939\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 94\n",
      "        ALL area: 14130.3 km2, 100.0 %\n",
      "       CAll area: 14120.7 km2, 99.932 %\n",
      "       IPSL area: 14120.7 km2, 99.932 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 9.6 km2\n",
      "Region P05:\n",
      "  ALL nr RGI-IDS: 2840\n",
      " CAll nr RGI-IDS: 2661\n",
      " IPSL nr RGI-IDS: 2663\n",
      "     CALL - IPSL: -2\n",
      "      ALL - CALL: 179\n",
      "        ALL area: 85463.9 km2, 100.0 %\n",
      "       CAll area: 84175.0 km2, 98.492 %\n",
      "       IPSL area: 84175.7 km2, 98.493 %\n",
      "     CALL - IPSL: -0.6 km2\n",
      "      ALL - CALL: 1288.8 km2\n",
      "Region P06:\n",
      "  ALL nr RGI-IDS: 2218\n",
      " CAll nr RGI-IDS: 2086\n",
      " IPSL nr RGI-IDS: 2086\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 132\n",
      "        ALL area: 1194.9 km2, 100.0 %\n",
      "       CAll area: 1109.2 km2, 92.822 %\n",
      "       IPSL area: 1109.2 km2, 92.822 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 85.8 km2\n",
      "Region P07:\n",
      "  ALL nr RGI-IDS: 3927\n",
      " CAll nr RGI-IDS: 3896\n",
      " IPSL nr RGI-IDS: 3896\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 31\n",
      "        ALL area: 2092.1 km2, 100.0 %\n",
      "       CAll area: 2091.1 km2, 99.949 %\n",
      "       IPSL area: 2091.1 km2, 99.949 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 1.1 km2\n",
      "Region P08:\n",
      "  ALL nr RGI-IDS: 1888\n",
      " CAll nr RGI-IDS: 1411\n",
      " IPSL nr RGI-IDS: 1411\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 477\n",
      "        ALL area: 1307.0 km2, 100.0 %\n",
      "       CAll area: 1135.4 km2, 86.869 %\n",
      "       IPSL area: 1135.4 km2, 86.869 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 171.6 km2\n",
      "Region P09:\n",
      "  ALL nr RGI-IDS: 98286\n",
      " CAll nr RGI-IDS: 96153\n",
      " IPSL nr RGI-IDS: 96160\n",
      "     CALL - IPSL: -7\n",
      "      ALL - CALL: 2133\n",
      "        ALL area: 98804.4 km2, 100.0 %\n",
      "       CAll area: 98049.6 km2, 99.236 %\n",
      "       IPSL area: 98052.7 km2, 99.239 %\n",
      "     CALL - IPSL: -3.1 km2\n",
      "      ALL - CALL: 754.8 km2\n",
      "Region P10:\n",
      "  ALL nr RGI-IDS: 2898\n",
      " CAll nr RGI-IDS: 2882\n",
      " IPSL nr RGI-IDS: 2882\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 16\n",
      "        ALL area: 2334.5 km2, 100.0 %\n",
      "       CAll area: 2333.6 km2, 99.963 %\n",
      "       IPSL area: 2333.6 km2, 99.963 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 0.9 km2\n",
      "Region P11:\n",
      "  ALL nr RGI-IDS: 15908\n",
      " CAll nr RGI-IDS: 15806\n",
      " IPSL nr RGI-IDS: 15806\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 102\n",
      "        ALL area: 29429.1 km2, 100.0 %\n",
      "       CAll area: 29375.5 km2, 99.818 %\n",
      "       IPSL area: 29375.5 km2, 99.818 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 53.6 km2\n",
      "Region P12:\n",
      "  ALL nr RGI-IDS: 3537\n",
      " CAll nr RGI-IDS: 3535\n",
      " IPSL nr RGI-IDS: 3535\n",
      "     CALL - IPSL: 0\n",
      "      ALL - CALL: 2\n",
      "        ALL area: 1161.8 km2, 100.0 %\n",
      "       CAll area: 1161.7 km2, 99.993 %\n",
      "       IPSL area: 1161.7 km2, 99.993 %\n",
      "     CALL - IPSL: 0.0 km2\n",
      "      ALL - CALL: 0.1 km2\n"
     ]
    }
   ],
   "source": [
    "if is_notebook:\n",
    "\n",
    "    #test_region = 'P07'\n",
    "    for test_region in provide_regions:\n",
    "        file_all = f\"commonly_running_glaciers_all_{test_region}.json\"\n",
    "        file_without_IPSL = f\"commonly_running_glaciers_without_IPSL_{test_region}.json\"\n",
    "    \n",
    "        with open(os.path.join(output_dir_region, file_all), 'r') as f:\n",
    "            rgi_ids_all_test = json.load(f)\n",
    "    \n",
    "        with open(os.path.join(output_dir_region, file_without_IPSL), 'r') as f:\n",
    "            rgi_ids_without_IPSL_test = json.load(f)\n",
    "\n",
    "        # all rgi_ids of region\n",
    "        rgi_ids_region_all = list(set(dict_rgis_preg[test_region]))\n",
    "        if test_region == 'P03': # omit connectiity level 2 from P03 (i.e., Greenland)\n",
    "            odf_preg = df_rgi.loc[rgi_ids_region_all]\n",
    "            odf_preg_sel = odf_preg.loc[odf_preg['Connect'] != 2]\n",
    "            rgi_ids_region_all = odf_preg_sel.index\n",
    "\n",
    "        all_area = df_rgi.loc[rgi_ids_region_all].Area.sum()\n",
    "        call_area = df_rgi.loc[rgi_ids_all_test].Area.sum()\n",
    "        ipsl_area = df_rgi.loc[rgi_ids_without_IPSL_test].Area.sum()\n",
    "        print(f'Region {test_region}:')\n",
    "        print(f'  ALL nr RGI-IDS: {len(rgi_ids_region_all)}')\n",
    "        print(f' CAll nr RGI-IDS: {len(rgi_ids_all_test)}')\n",
    "        print(f' IPSL nr RGI-IDS: {len(rgi_ids_without_IPSL_test)}')\n",
    "        print(f'     CALL - IPSL: {len(rgi_ids_all_test) - len(rgi_ids_without_IPSL_test)}')\n",
    "        print(f'      ALL - CALL: {len(rgi_ids_region_all)- len(rgi_ids_all_test)}')\n",
    "        print(f'        ALL area: {all_area:.1f} km2, {100 / all_area * all_area:.1f} %')\n",
    "        print(f'       CAll area: {call_area:.1f} km2, {100 / all_area * call_area:.3f} %')\n",
    "        print(f'       IPSL area: {ipsl_area:.1f} km2, {100 / all_area * ipsl_area:.3f} %')\n",
    "        print(f'     CALL - IPSL: '\n",
    "              f'{df_rgi.loc[rgi_ids_all_test].Area.sum() -df_rgi.loc[rgi_ids_without_IPSL_test].Area.sum():.1f}'\n",
    "              f' km2')\n",
    "        print(f'      ALL - CALL: '\n",
    "              f'{df_rgi.loc[rgi_ids_region_all].Area.sum() - df_rgi.loc[rgi_ids_all_test].Area.sum():.1f}'\n",
    "              f' km2')  "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python [conda env:oggm_env]",
   "language": "python",
   "name": "conda-env-oggm_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
